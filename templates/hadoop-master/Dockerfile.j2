#jinja2: trim_blocks: True, lstrip_blocks: True
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ARG PROJECT_VERSION
FROM hadoop-testing/base-ubuntu-2004:$PROJECT_VERSION

ARG ZEPPELIN_VERSION
ARG ZOOKEEPER_VERSION
ARG HADOOP_VERSION
ARG HIVE_VERSION
ARG SPARK_VERSION
ARG SPARK_BINARY_VERSION
ARG FLINK_VERSION
ARG SCALA_BINARY_VERSION
ARG KYUUBI_VERSION
ARG MYSQL_JDBC_VERSION
ARG LOKI_APPENDER_VERSION
ARG RANGER_VERSION
ARG ICEBERG_VERSION
ARG HUDI_VERSION
ARG TRINO_VERSION

ENV ZEPPELIN_HOME=/opt/zeppelin
ENV ZEPPELIN_CONF_DIR=/etc/zeppelin/conf
ENV ZOOKEEPER_HOME=/opt/zookeeper
ENV ZOOCFGDIR=/etc/zookeeper/conf
ENV HADOOP_HOME=/opt/hadoop
ENV HADOOP_CONF_DIR=/etc/hadoop/conf
ENV HADOOP_CLASSPATH=${HADOOP_HOME}/share/hadoop/client/*
ENV HIVE_HOME=/opt/hive
ENV HIVE_CONF_DIR=/etc/hive/conf
ENV SPARK_HOME=/opt/spark
ENV SPARK_CONF_DIR=/etc/spark/conf
{% if flink_enabled %}
ENV FLINK_HOME=/opt/flink
ENV FLINK_CONF_DIR=/etc/flink/conf
{% endif %}
ENV KYUUBI_HOME=/opt/kyuubi
ENV KYUUBI_CONF_DIR=/etc/kyuubi/conf
{% if ranger_enabled %}
ENV RANGER_HOME=/opt/ranger
{% endif %}
{% if trino_enabled %}
ENV TRINO_HOME=/opt/trino
{% endif %}
ENV MYSQL_JDBC_VERSION=${MYSQL_JDBC_VERSION}
ENV PATH=${KYUUBI_HOME}/bin:${SPARK_HOME}/bin:${HIVE_HOME}/bin:${HADOOP_HOME}/bin:${ZEPPELIN_HOME}/bin:${ZOOKEEPER_HOME}/bin:${PATH}

{% if zeppelin_enabled %}
ADD download/zeppelin-${ZEPPELIN_VERSION}-bin-netinst.tgz /opt
{% endif %}
ADD download/apache-zookeeper-${ZOOKEEPER_VERSION}-bin.tar.gz /opt
ADD download/hadoop-${HADOOP_VERSION}.tar.gz /opt
ADD download/apache-hive-${HIVE_VERSION}-bin.tar.gz /opt
ADD download/spark-${SPARK_VERSION}-bin-hadoop3.tgz /opt
{% if flink_enabled %}
ADD download/flink-${FLINK_VERSION}-bin-scala_${SCALA_BINARY_VERSION}.tgz /opt
{% endif %}
ADD download/apache-kyuubi-${KYUUBI_VERSION}-bin.tgz /opt
{% if ranger_enabled %}
ADD download/ranger-${RANGER_VERSION}-admin.tar.gz /opt
{% endif %}
{% if trino_enabled %}
ADD download/trino-server-${TRINO_VERSION}.tar.gz /opt
{% endif %}

# Copy configuration files
COPY ./files /

RUN chmod 600 /root/.ssh/id_rsa_hadoop_testing

RUN ln -snf ${HIVE_CONF_DIR}/hive-site.xml ${SPARK_CONF_DIR}/hive-site.xml && \
    ln -snf ${HIVE_CONF_DIR}/hive-site.xml ${KYUUBI_CONF_DIR}/hive-site.xml

RUN ln -snf /opt/apache-zookeeper-${ZOOKEEPER_VERSION}-bin ${ZOOKEEPER_HOME} && \
    ln -snf /opt/hadoop-${HADOOP_VERSION} ${HADOOP_HOME} && \
    ln -snf /opt/apache-hive-${HIVE_VERSION}-bin ${HIVE_HOME} && \
    ln -snf /opt/spark-${SPARK_VERSION}-bin-hadoop3 ${SPARK_HOME} && \
    ln -snf /opt/apache-kyuubi-${KYUUBI_VERSION}-bin ${KYUUBI_HOME}

{% if flink_enabled %}
RUN ln -snf /opt/flink-${FLINK_VERSION} ${FLINK_HOME}
{% endif %}

{% if zeppelin_enabled %}
RUN ln -snf /opt/zeppelin-${ZEPPELIN_VERSION}-bin-netinst ${ZEPPELIN_HOME} && \
    mkdir -p /var/log/zeppelin && \
    mkdir -p /var/run/zeppelin && \
    mkdir -p /var/run/zeppelin/webapps && \
    mkdir -p /var/run/zeppelin/pid && \
    mkdir -p /var/lib/zeppelin && \
    mkdir -p /var/lib/zeppelin/notebook && \
    cp -R ${ZEPPELIN_HOME}/notebook/* /var/lib/zeppelin/notebook && \
    chown -R 6014:6014 /etc/zeppelin && \
    chown -R 6014:6014 /var/run/zeppelin && \
    chown -R 6014:6014 /var/lib/zeppelin && \
    chown -R 6014:6014 /var/log/zeppelin
{% endif %}
{% if ranger_enabled %}
RUN ln -snf /opt/ranger-${RANGER_VERSION}-admin ${RANGER_HOME}
{% endif %}
{% if trino_enabled %}
RUN ln -snf /opt/trino-server-${TRINO_VERSION} ${TRINO_HOME}
{% endif %}

ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${HIVE_HOME}/lib/
{% if ranger_enabled %}
ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${RANGER_HOME}/
{% endif %}
{% if iceberg_enabled %}
ADD download/iceberg-spark-runtime-${SPARK_BINARY_VERSION}_${SCALA_BINARY_VERSION}-${ICEBERG_VERSION}.jar ${SPARK_HOME}/jars/
{% endif %}
{% if hudi_enabled %}
ADD download/hudi-spark${SPARK_BINARY_VERSION}-bundle_${SCALA_BINARY_VERSION}-${HUDI_VERSION}.jar ${SPARK_HOME}/jars/
{% endif %}
{% if flink_enabled %}
ADD download/jcl-over-slf4j-1.7.36.jar ${FLINK_HOME}/lib/
ADD download/flink-sql-connector-hive-${HIVE_VERSION}_${SCALA_BINARY_VERSION}-${FLINK_VERSION}.jar ${FLINK_HOME}/lib/
{% endif %}
{% if trino_enabled %}
ADD --chmod=755 download/trino-cli-${TRINO_VERSION}-executable.jar ${TRINO_HOME}/bin/trino-cli
{% endif %}

ADD download/log4j2-appender-nodep-${LOKI_APPENDER_VERSION}.jar ${HIVE_HOME}/lib/
ADD download/log4j2-appender-nodep-${LOKI_APPENDER_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/log4j2-appender-nodep-${LOKI_APPENDER_VERSION}.jar ${KYUUBI_HOME}/jars/
ADD download/kyuubi-spark-connector-tpch_${SCALA_BINARY_VERSION}-${KYUUBI_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/kyuubi-spark-connector-tpcds_${SCALA_BINARY_VERSION}-${KYUUBI_VERSION}.jar ${SPARK_HOME}/jars/

{% if ranger_enabled %}
# chown would doulbe the size of the image by introduce a new layer, but ranger seems does not work without chmod
RUN chown -R ranger:hadoop /opt/ranger-${RANGER_VERSION}-admin
{% endif %}

RUN /opt/hadoop-init.d/init-hdfs.sh
{% if trino_enabled %}
RUN /opt/trino-init.d/init-workdir.sh
{% endif %}

# Zookeeper ports
EXPOSE 2181

# HDFS ports
EXPOSE 1004 1006 8020 9866 9867 9870 9864 50470

# YARN ports
EXPOSE 8030 8031 8032 8033 8040 8041 8042 8088 10020 19888

# HIVE ports
EXPOSE 9083 10000

# SPARK ports
EXPOSE 18080

# Flink ports
EXPOSE 8082

{% if ranger_enabled %}
EXPOSE 6080
{% endif %}

{% if trino_enabled %}
EXPOSE 18081
{% endif %}

CMD ["supervisord", "-c", "/etc/supervisord.conf"]
ENTRYPOINT ["/opt/entrypoint.sh"]
