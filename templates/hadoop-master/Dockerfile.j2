#jinja2: trim_blocks: True, lstrip_blocks: True
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ARG PROJECT_VERSION
FROM hadoop-testing/base-ubuntu-2004:$PROJECT_VERSION

ARG ZEPPELIN_VERSION
ARG ZOOKEEPER_VERSION
ARG HADOOP_VERSION
ARG HIVE_VERSION
ARG SPARK_VERSION
ARG SPARK_BINARY_VERSION
ARG FLINK_VERSION
ARG FLINK_BINARY_VERSION
ARG FLINK_HIVE_VERSION
ARG SPARK_SCALA_BINARY_VERSION
ARG KYUUBI_VERSION
ARG MYSQL_JDBC_VERSION
ARG LOKI_APPENDER_VERSION
ARG RANGER_VERSION
ARG ICEBERG_VERSION
ARG HUDI_VERSION
ARG KAFKA_VERSION
ARG TRINO_VERSION
ARG PARQUET_VERSION

ENV ZEPPELIN_HOME=/opt/zeppelin
ENV ZEPPELIN_CONF_DIR=/etc/zeppelin/conf
ENV ZOOKEEPER_HOME=/opt/zookeeper
ENV ZOOCFGDIR=/etc/zookeeper/conf
ENV HADOOP_HOME=/opt/hadoop
ENV HADOOP_CONF_DIR=/etc/hadoop/conf
ENV LD_LIBRARY_PATH=${HADOOP_HOME}/lib/native
ENV HIVE_HOME=/opt/hive
ENV HIVE_CONF_DIR=/etc/hive/conf
{% if spark_enabled %}
ENV SPARK_HOME=/opt/spark
ENV SPARK_CONF_DIR=/etc/spark/conf
{% endif %}
{% if flink_enabled %}
ENV FLINK_HOME=/opt/flink
ENV FLINK_CONF_DIR=/etc/flink/conf
{% endif %}
ENV KYUUBI_HOME=/opt/kyuubi
ENV KYUUBI_CONF_DIR=/etc/kyuubi/conf
{% if ranger_enabled %}
ENV RANGER_HOME=/opt/ranger
{% endif %}
{% if trino_enabled %}
ENV TRINO_HOME=/opt/trino
{% endif %}
{% if parquet_enabled %}
ENV PARQUET_HOME=/opt/parquet
{% endif %}
ENV MYSQL_JDBC_VERSION=${MYSQL_JDBC_VERSION}
ENV PATH=${HIVE_HOME}/bin:${HADOOP_HOME}/bin:${ZEPPELIN_HOME}/bin:${ZOOKEEPER_HOME}/bin:${PATH}
{% if spark_enabled %}
ENV PATH=${SPARK_HOME}/bin:${PATH}
{% endif %}
{% if flink_enabled %}
ENV PATH=${FLINK_HOME}/bin:${PATH}
{% endif %}
ENV PATH=${KYUUBI_HOME}/bin:${PATH}
{% if parquet_enabled %}
ENV PATH=${PARQUET_HOME}/bin:${PATH}
{% endif %}

{% if zeppelin_enabled %}
ADD download/zeppelin-${ZEPPELIN_VERSION}-bin{{ '-%s' % zeppelin_custom_name if zeppelin_custom_name }}.tgz /opt
{% endif %}
ADD download/apache-zookeeper-${ZOOKEEPER_VERSION}-bin.tar.gz /opt
ADD download/hadoop-${HADOOP_VERSION}.tar.gz /opt
ADD download/apache-hive-${HIVE_VERSION}-bin.tar.gz /opt
{% if spark_enabled %}
ADD download/spark-${SPARK_VERSION}-bin-{{ spark_custom_name }}.tgz /opt
{% endif %}
{% if flink_enabled %}
ADD download/flink-${FLINK_VERSION}-bin-scala_2.12.tgz /opt
{% endif %}
ADD download/apache-kyuubi-${KYUUBI_VERSION}-bin.tgz /opt
{% if ranger_enabled %}
ADD download/ranger-${RANGER_VERSION}-admin.tar.gz /opt
{% endif %}
{% if trino_enabled %}
ADD download/trino-server-${TRINO_VERSION}.tar.gz /opt
{% endif %}

# Copy configuration files
COPY ./files /

RUN chmod 600 /root/.ssh/id_rsa_hadoop_testing

RUN ln -snf /opt/apache-zookeeper-${ZOOKEEPER_VERSION}-bin ${ZOOKEEPER_HOME} && \
    ln -snf /opt/hadoop-${HADOOP_VERSION} ${HADOOP_HOME} && \
    ln -snf /opt/apache-hive-${HIVE_VERSION}-bin ${HIVE_HOME} && \
    ln -snf /opt/apache-kyuubi-${KYUUBI_VERSION}-bin ${KYUUBI_HOME} && \
    ln -snf ${HIVE_CONF_DIR}/hive-site.xml ${KYUUBI_CONF_DIR}/hive-site.xml && \
    mkdir -p /var/log/kyuubi && chmod -R 777 /var/log/kyuubi

ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${KYUUBI_HOME}/jars/

{% if spark_enabled %}
RUN ln -snf /opt/spark-${SPARK_VERSION}-bin-{{ spark_custom_name }} ${SPARK_HOME} && \
    ln -snf ${HIVE_CONF_DIR}/hive-site.xml ${SPARK_CONF_DIR}/hive-site.xml

ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${SPARK_HOME}/jars/
{% endif %}

{% if flink_enabled %}
RUN ln -snf /opt/flink-${FLINK_VERSION} ${FLINK_HOME} && \
    ln -snf ${HIVE_CONF_DIR}/hive-site.xml ${FLINK_CONF_DIR}/hive-site.xml && \
    ln -s ${HADOOP_HOME}/share/hadoop/client/hadoop-client-api-${HADOOP_VERSION}.jar ${FLINK_HOME}/lib/ && \
    ln -s ${HADOOP_HOME}/share/hadoop/client/hadoop-client-runtime-${HADOOP_VERSION}.jar ${FLINK_HOME}/lib/ && \
    mkdir /var/log/flink && chmod -R 777 /var/log/flink
{% endif %}

{% if zeppelin_enabled %}
RUN ln -snf /opt/zeppelin-${ZEPPELIN_VERSION}-bin{{ '-%s' % zeppelin_custom_name if zeppelin_custom_name }} ${ZEPPELIN_HOME} && \
    mkdir -p /var/log/zeppelin && \
    mkdir -p /var/run/zeppelin && \
    mkdir -p /var/run/zeppelin/webapps && \
    mkdir -p /var/run/zeppelin/pid && \
    mkdir -p /var/lib/zeppelin && \
    mkdir -p /var/lib/zeppelin/notebook && \
    cp -R ${ZEPPELIN_HOME}/notebook/* /var/lib/zeppelin/notebook && \
    chown -R 6014:6014 /etc/zeppelin && \
    chown -R 6014:6014 /var/run/zeppelin && \
    chown -R 6014:6014 /var/lib/zeppelin && \
    chown -R 6014:6014 /var/log/zeppelin

ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${ZEPPELIN_HOME}/interpreter/jdbc/
ADD download/kyuubi-hive-jdbc-shaded-${KYUUBI_VERSION}.jar ${ZEPPELIN_HOME}/interpreter/jdbc/
RUN ln -s ${HIVE_HOME}/jdbc/hive-jdbc-${HIVE_VERSION}-standalone.jar ${ZEPPELIN_HOME}/interpreter/jdbc/ && \
    ln -s ${HADOOP_HOME}/share/hadoop/client/hadoop-client-api-${HADOOP_VERSION}.jar ${ZEPPELIN_HOME}/interpreter/jdbc/ && \
    ln -s ${HADOOP_HOME}/share/hadoop/client/hadoop-client-runtime-${HADOOP_VERSION}.jar ${ZEPPELIN_HOME}/interpreter/jdbc/
{% endif %}

{% if ranger_enabled %}
{% endif %}
{% if ranger_enabled %}
RUN ln -snf /opt/ranger-${RANGER_VERSION}-admin ${RANGER_HOME}
{% endif %}
{% if trino_enabled %}
RUN ln -snf /opt/trino-server-${TRINO_VERSION} ${TRINO_HOME}
{% endif %}

ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${HIVE_HOME}/lib/
{% if ranger_enabled %}
ADD download/mysql-connector-j-${MYSQL_JDBC_VERSION}.jar ${RANGER_HOME}/
{% endif %}
{% if spark_enabled and iceberg_enabled %}
ADD download/iceberg-spark-runtime-${SPARK_BINARY_VERSION}_${SPARK_SCALA_BINARY_VERSION}-${ICEBERG_VERSION}.jar ${SPARK_HOME}/jars/
{% endif %}
{% if flink_enabled and iceberg_enabled %}
ADD download/iceberg-flink-runtime-${FLINK_BINARY_VERSION}-${ICEBERG_VERSION}.jar ${FLINK_HOME}/lib/
{% endif %}
{% if spark_enabled and hudi_enabled %}
ADD download/hudi-spark${SPARK_BINARY_VERSION}-bundle_${SPARK_SCALA_BINARY_VERSION}-${HUDI_VERSION}.jar ${SPARK_HOME}/jars/
{% endif %}
{% if flink_enabled %}
ADD download/jcl-over-slf4j-1.7.36.jar ${FLINK_HOME}/lib/
ADD download/flink-sql-connector-hive-${FLINK_HIVE_VERSION}_2.12-${FLINK_VERSION}.jar ${FLINK_HOME}/lib/
{% endif %}
{% if trino_enabled %}
ADD --chmod=755 download/trino-cli-${TRINO_VERSION}-executable.jar ${TRINO_HOME}/bin/trino-cli
{% endif %}
{% if parquet_enabled %}
ADD download/parquet-cli-${PARQUET_VERSION}-runtime.jar ${PARQUET_HOME}/jars/
{% endif %}

ADD download/log4j2-appender-nodep-${LOKI_APPENDER_VERSION}.jar ${HIVE_HOME}/lib/
ADD download/log4j2-appender-nodep-${LOKI_APPENDER_VERSION}.jar ${KYUUBI_HOME}/jars/

{% if spark_enabled %}
ADD download/kyuubi-spark-connector-tpch_${SPARK_SCALA_BINARY_VERSION}-${KYUUBI_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/kyuubi-spark-connector-tpcds_${SPARK_SCALA_BINARY_VERSION}-${KYUUBI_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/log4j2-appender-nodep-${LOKI_APPENDER_VERSION}.jar ${SPARK_HOME}/jars/
{% endif %}

{% if spark_enabled and kafka_enabled %}
ADD download/kafka-clients-${KAFKA_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/spark-sql-kafka-0-10_${SPARK_SCALA_BINARY_VERSION}-${SPARK_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/spark-token-provider-kafka-0-10_${SPARK_SCALA_BINARY_VERSION}-${SPARK_VERSION}.jar ${SPARK_HOME}/jars/
ADD download/commons-pool2-2.12.1.jar ${SPARK_HOME}/jars/
{% endif %}

{% if ranger_enabled %}
# chown would doulbe the size of the image by introduce a new layer, but ranger seems does not work without chmod
RUN chown -R ranger:hadoop /opt/ranger-${RANGER_VERSION}-admin
{% endif %}

RUN /opt/hadoop-init.d/init-hdfs.sh
{% if trino_enabled %}
RUN /opt/trino-init.d/init-workdir.sh
{% endif %}

# Zookeeper ports
EXPOSE 2181

# HDFS ports
EXPOSE 8020 9864 9866 9867 9870

# YARN ports
EXPOSE 8030 8031 8032 8033 8040 8041 8042 8088 10020 19888

# HIVE ports
EXPOSE 9083 10000

# SPARK ports
EXPOSE 18080

# Flink ports
EXPOSE 8082

{% if ranger_enabled %}
EXPOSE 6080
{% endif %}

{% if trino_enabled %}
EXPOSE 18081
{% endif %}

CMD ["supervisord", "-c", "/etc/supervisord.conf"]
ENTRYPOINT ["/opt/entrypoint.sh"]
